{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[2.2122064 0.7740038]\n",
      " [1.0434403 1.1839255]]\n",
      "<NDArray 2x2 @cpu(0)> - \n",
      "[[4.893857  0.5990819]\n",
      " [1.0887678 1.4016796]]\n",
      "<NDArray 2x2 @cpu(0)>\n",
      "<class 'mxnet.ndarray.ndarray.NDArray'> -> <class 'mxnet.ndarray.ndarray.NDArray'>\n",
      "\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "<NDArray 2x2 @cpu(0)> -> \n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "<NDArray 2x2 @cpu(0)>\n",
      "\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "<NDArray 2x2 @cpu(0)> -> \n",
      "[[0.25 0.25]\n",
      " [0.25 0.25]]\n",
      "<NDArray 2x2 @cpu(0)>\n",
      "\n",
      "[[1.1061032  0.3870019 ]\n",
      " [0.5217202  0.59196275]]\n",
      "<NDArray 2x2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import mxnet as mx\n",
    "from mxnet import autograd\n",
    "\n",
    "with autograd.record():\n",
    "    x = mx.random.randn(2, 2)\n",
    "    x.attach_grad()\n",
    "\n",
    "    y = x ** 2\n",
    "    y.attach_grad()\n",
    "\n",
    "    z = y.mean()\n",
    "    print(f\"{x} - {y}\")\n",
    "\n",
    "print(f\"{type(x)} -> {type(y)}\")\n",
    "\n",
    "print(f\"{x.grad} -> {y.grad}\")\n",
    "\n",
    "z.backward()\n",
    "\n",
    "print(f\"{x.grad} -> {y.grad}\")\n",
    "print(f\"{x / 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> -> <class 'torch.Tensor'>\n",
      "None -> None\n",
      "tensor([[ 1.0038,  0.3119],\n",
      "        [-1.0436, -0.4164]]) -> None\n",
      "tensor([[ 1.0038,  0.3119],\n",
      "        [-1.0436, -0.4164]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch as tt\n",
    "\n",
    "x = tt.randn(2, 2, requires_grad=True)\n",
    "\n",
    "y = x ** 2\n",
    "\n",
    "z = y.mean()\n",
    "\n",
    "print(f\"{type(x)} -> {type(y)}\")\n",
    "\n",
    "print(f\"{x.grad} -> {y.grad}\")\n",
    "\n",
    "z.backward()\n",
    "\n",
    "print(f\"{x.grad} -> {y.grad}\")\n",
    "print(f\"{x / 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.2",
    "jupytext_version": "0.8.6"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
